{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/llm/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from datasets import load_from_disk\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "random.seed(42)\n",
    "\n",
    "'''data'''\n",
    "data = json.load(open('../data/raw/wikipedia_documents.json'))\n",
    "wiki = pd.DataFrame(data).T\n",
    "dataset = load_from_disk(\"../data/raw/train_dataset/\")\n",
    "train_df = pd.DataFrame(dataset['train'])\n",
    "valid_df = pd.DataFrame(dataset['validation'])\n",
    "mrc = pd.concat([train_df, valid_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "\n",
    "prompts = {\n",
    "    \"query\": \"query: \",        # 검색 쿼리 프롬프트\n",
    "    \"passage\": \"passage: \"     # 문서 패시지 프롬프트\n",
    "}\n",
    "\n",
    "'''inference'''\n",
    "model_name = \"nlpai-lab/KoE5\"\n",
    "model = SentenceTransformer(\n",
    "    model_name_or_path=model_name, \n",
    "    device='cuda', \n",
    "    similarity_fn_name='dot',\n",
    "    truncate_dim=512,\n",
    "    model_kwargs={\"torch_dtype\": torch.bfloat16},\n",
    "    prompts=prompts,\n",
    "    )\n",
    "queries = mrc['question'].tolist()[:5]\n",
    "wiki_list = wiki['text'].tolist()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(queries), len(wiki_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window_tokenize(text, tokenizer, max_length, stride):\n",
    "    tokens = tokenizer(\n",
    "        text, truncation=True, max_length=max_length, stride=stride, return_overflowing_tokens=True\n",
    "    )\n",
    "    \n",
    "    # 첫 번째 청크를 리스트로 추가\n",
    "    chunks = [tokens[\"input_ids\"]]\n",
    "    \n",
    "    # 초과된 토큰이 있을 경우 반복 처리\n",
    "    while \"overflowing_tokens\" in tokens and len(tokens[\"overflowing_tokens\"]) > 0:\n",
    "        # 초과된 토큰을 기반으로 새로운 청크 생성\n",
    "        tokens = tokenizer(\n",
    "            tokenizer.decode(tokens[\"overflowing_tokens\"]), \n",
    "            truncation=True, max_length=max_length, stride=stride, return_overflowing_tokens=True\n",
    "        )\n",
    "        chunks.append(tokens[\"input_ids\"])  # 각 청크 추가\n",
    "    \n",
    "    # 각 청크를 개별적으로 decode하여 문자열로 변환 후 반환\n",
    "    return [tokenizer.decode(chunk, skip_special_tokens=True) for chunk in chunks]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc:  이 문서는 나라 목록이며, 전 세계 206개 나라의 각 현황과 주권 승인 정보를 개요 형태로 나열하고 있다.\n",
      "\n",
      "이 목록은 명료화를 위해 두 부분으로 나뉘어 있다.\n",
      "\n",
      "# 첫 번째 부분은 바티칸 시국과 팔레스타인을 포함하여 유엔 등 국제 기구에 가입되어 국제적인 승인을 널리 받았다고 여기는 195개 나라를 나열하고 있다.\n",
      "# 두 번째 부분은 일부 지역의 주권을 사실상 (데 팍토) 행사하고 있지만, 아직 국제적인 승인을 널리 받지 않았다고 여기는 11개 나라를 나열하고 있다.\n",
      "\n",
      "두 목록은 모두 가나다 순이다.\n",
      "\n",
      "일부 국가의 경우 국가로서의 자격에 논쟁의 여부가 있으며, 이 때문에 이러한 목록을 엮는 것은 매우 어렵고 논란이 생길 수 있는 과정이다. 이 목록을 구성하고 있는 국가를 선정하는 기준에 대한 정보는 \"포함 기준\" 단락을 통해 설명하였다. 나라에 대한 일반적인 정보는 \"국가\" 문서에서 설명하고 있다.\n",
      "tokens:\n",
      "dict_keys(['input_ids', 'attention_mask', 'overflow_to_sample_mapping'])\n"
     ]
    }
   ],
   "source": [
    "doc = wiki['text'].tolist()[0]\n",
    "\n",
    "tokenizer = model.tokenizer\n",
    "max_length = min(model.max_seq_length, model[0].auto_model.config.max_position_embeddings)  # 최대 시퀀스 길이\n",
    "stride = int(max_length * 0.5)  # 50% 겹침\n",
    "\n",
    "tokens = tokenizer(\n",
    "    doc, truncation=True, max_length=max_length, stride=stride, return_overflowing_tokens=True\n",
    ")\n",
    "\n",
    "print(\"doc: \", doc)\n",
    "print('tokens:')\n",
    "print(tokens.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_pooling_include_prompt(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 Transformer({'max_seq_length': 512, 'do_lower_case': False}) with Transformer model: XLMRobertaModel \n",
      "1 Pooling({'word_embedding_dimension': 1024, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': False})\n",
      "2 Normalize()\n"
     ]
    }
   ],
   "source": [
    "# print(model.max_seq_length)\n",
    "# print(model[0].auto_model.config.max_position_embeddings)\n",
    "\n",
    "# print(model.get_max_seq_length())\n",
    "# print(model.get_sentence_embedding_dimension())\n",
    "# print(model.similarity_fn_name)\n",
    "\n",
    "# print(model.tokenizer)\n",
    "\n",
    "# if hasattr(model[0].auto_model.config, 'instructor'):\n",
    "#     print(\"This is an INSTRUCTOR model.\")\n",
    "# else:\n",
    "#     print(\"This is not an INSTRUCTOR model.\")\n",
    "for i,x in enumerate(model):\n",
    "    print(i, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pool = model.start_multi_process_pool()\n",
    "# encoded_query = model.encode_multi_process(\n",
    "#     sentences=queries,\n",
    "#     pool=pool,\n",
    "#     show_progress_bar=True,\n",
    "#     )\n",
    "# encoded_wiki = model.encode_multi_process(\n",
    "#     sentences=wiki_list, \n",
    "#     pool=pool,\n",
    "#     show_progress_bar=True,\n",
    "#     )\n",
    "\n",
    "# model.stop_multi_process_pool(pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(queries))\n",
    "# print(len(wiki_list))\n",
    "\n",
    "encoded_query = model.encode(queries, prompt_name=\"query\", show_progress_bar=True)\n",
    "encoded_wiki = model.encode(wiki_list, prompt_name=\"passage\", show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4192\n",
      "60613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches:   0%|          | 0/131 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 131/131 [00:09<00:00, 14.40it/s]\n",
      "Batches:  10%|▉         | 186/1895 [03:16<30:05,  1.06s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m      7\u001b[0m     encoded_query \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mencode(queries, prompt_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m, show_progress_bar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m----> 8\u001b[0m     encoded_wiki \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwiki_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpassage\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/llm/lib/python3.11/site-packages/sentence_transformers/SentenceTransformer.py:650\u001b[0m, in \u001b[0;36mSentenceTransformer.encode\u001b[0;34m(self, sentences, prompt_name, prompt, batch_size, show_progress_bar, output_value, precision, convert_to_numpy, convert_to_tensor, device, normalize_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    648\u001b[0m             \u001b[38;5;66;03m# fixes for #522 and #487 to avoid oom problems on gpu with large datasets\u001b[39;00m\n\u001b[1;32m    649\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m convert_to_numpy:\n\u001b[0;32m--> 650\u001b[0m                 embeddings \u001b[38;5;241m=\u001b[39m \u001b[43membeddings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    652\u001b[0m         all_embeddings\u001b[38;5;241m.\u001b[39mextend(embeddings)\n\u001b[1;32m    654\u001b[0m all_embeddings \u001b[38;5;241m=\u001b[39m [all_embeddings[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39margsort(length_sorted_idx)]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "print(len(queries))\n",
    "print(len(wiki_list))\n",
    "\n",
    "with torch.no_grad():\n",
    "    encoded_query = model.encode(queries, prompt_name=\"query\", show_progress_bar=True)\n",
    "    encoded_wiki = model.encode(wiki_list, prompt_name=\"passage\", show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing query 1/1:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start idx: 0\n",
      "batch size: 5\n",
      "wiki list len: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing query 1/1:  50%|█████     | 1/2 [00:05<00:05,  5.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5,)\n",
      "start idx: 5\n",
      "batch size: 5\n",
      "wiki list len: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing query 1/1: 100%|██████████| 2/2 [00:09<00:00,  4.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5,)\n",
      "[array([70.44482, 73.37528, 70.29869, 73.86983, 63.21244], dtype=float32), array([64.66734, 62.94172, 72.91665, 69.45655, 69.65785], dtype=float32)]\n",
      "[70.44482 73.37528 70.29869 73.86983 63.21244 64.66734 62.94172 72.91665\n",
      " 69.45655 69.65785]\n",
      "[3 1 7 0 2]\n",
      "idx: 3\n",
      "wiki: 신라 지증왕 4년(503년)에 만들어진 것으로 추정되며, 1989년에 발견되었다. 발견 당시 신라시대 비석 중 현존하는 최고(最古)의 비석이었으나, 2009년 9월에 501년 혹은\n",
      "correct context: 항일의병장인 이교문 (李敎文)의 손자이자 이일의 아들이다. 5대조 이유원이 보성군 문덕면 가내마을에 정착하였고 그의 아들들 중 이용순의 고조할아버지인 이기대(李箕大)는 저명한 성리\n",
      "idx: 1\n",
      "wiki: 원래 베트남 지역을 통치하던 쩐 왕조는 대대로 명나라에 공물을 바치는 속국이었다. 하지만 1400년에 쩐 왕조의 장군 호꾸이리가 반란을 일으켜 쩐 왕가를 대거 학살한 다음 제위에 \n",
      "correct context: 항일의병장인 이교문 (李敎文)의 손자이자 이일의 아들이다. 5대조 이유원이 보성군 문덕면 가내마을에 정착하였고 그의 아들들 중 이용순의 고조할아버지인 이기대(李箕大)는 저명한 성리\n",
      "idx: 7\n",
      "wiki: 1600년(선조 33년) 의인왕후 박씨가 승하하자 왕비릉인 유릉(裕陵)의 터로 정해진 곳이다.\n",
      "\n",
      "1608년(선조 41년) 선조가 승하하고 광해군이 즉위하면서 능을 건원릉의 서편에 \n",
      "correct context: 항일의병장인 이교문 (李敎文)의 손자이자 이일의 아들이다. 5대조 이유원이 보성군 문덕면 가내마을에 정착하였고 그의 아들들 중 이용순의 고조할아버지인 이기대(李箕大)는 저명한 성리\n",
      "idx: 0\n",
      "wiki: 경주시 황남동 미추왕릉 지구에 있는 삼국시대 신라 무덤인 황남대총에서 발견된 금관이다. 신라 금관을 대표하는 것으로 높이 27.5cm, 아래로 늘어뜨린 드리개(수식) 길이는 13∼\n",
      "correct context: 항일의병장인 이교문 (李敎文)의 손자이자 이일의 아들이다. 5대조 이유원이 보성군 문덕면 가내마을에 정착하였고 그의 아들들 중 이용순의 고조할아버지인 이기대(李箕大)는 저명한 성리\n",
      "idx: 2\n",
      "wiki: 공산주의 국가의 연합조직인 바르샤바 조약 기구가 설립되어 냉전의 시대가 시작되면서 유럽 육군/제7군(USAREUR/7th US Army) 예하 두개 군단(다른 하나는 제5(V)군단\n",
      "correct context: 항일의병장인 이교문 (李敎文)의 손자이자 이일의 아들이다. 5대조 이유원이 보성군 문덕면 가내마을에 정착하였고 그의 아들들 중 이용순의 고조할아버지인 이기대(李箕大)는 저명한 성리\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "queries = queries[:1]\n",
    "wiki_list = wiki_list[:10]\n",
    "\n",
    "for i in range(len(queries)):\n",
    "    query_embedding = model.encode(queries[i], prompt_name=\"web_search_query\")\n",
    "\n",
    "    # 배치로 document embedding을 처리\n",
    "    all_scores = []\n",
    "    for start_idx in tqdm(range(0, len(wiki_list), batch_size), desc=f\"Processing query {i+1}/{len(queries)}\"):\n",
    "        print(f'start idx: {start_idx}')\n",
    "        print(f'batch size: {batch_size}')\n",
    "        print(f'wiki list len: {len(wiki_list)}')\n",
    "        batch_wiki_list = wiki_list[start_idx:start_idx + batch_size]\n",
    "        document_embeddings = model.encode(batch_wiki_list)\n",
    "        scores = (query_embedding @ document_embeddings.T) * 100\n",
    "        print(scores.shape)\n",
    "        all_scores.append(scores)\n",
    "    print(all_scores)\n",
    "\n",
    "    # 점수 결합\n",
    "    all_scores = np.concatenate(all_scores, axis=-1)\n",
    "    print(all_scores)\n",
    "    \n",
    "    # 상위 top_k 문서 찾기\n",
    "    top_indices = np.argsort(all_scores)[::-1][:top_k]\n",
    "    print(top_indices)\n",
    "    \n",
    "    correct = False\n",
    "    for idx in top_indices:\n",
    "        print(f'idx: {idx}')\n",
    "        print(f'wiki: {wiki_list[idx][:100]}')\n",
    "        print(f'correct context: {correct_contexts[i][:100]}')\n",
    "        if correct_contexts[idx] == wiki_list[idx]:  # 정답이 포함되어 있는지 확인\n",
    "            correct = True\n",
    "            correct_count += 1  # 정답이 포함되면 카운트 증가\n",
    "            break\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
