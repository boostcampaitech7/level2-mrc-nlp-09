{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augmentation - Synthetic Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers\n",
    "!pip install torch\n",
    "!pip install accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading shards: 100%|██████████| 4/4 [05:59<00:00, 89.88s/it] \n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:09<00:00,  2.35s/it]\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Question: 대통령을 포함한 미국의 행정부 견제권을 갖는 국가 기관은?\n",
      "Paraphrased Question: 질문: 대통령을 포함한 미국의 행정부 견제권을 갖는 국가 기관은?\n",
      "이 질문을 다른 표현으로 바꿔 주세요:\n",
      "새로운 질문: 미국 헌법 1조에 따르면, 대통령의 권한을 제한하는 국가기관은 무엇입니까? 2.\n",
      "이 문제에 대한 답을 찾는 데 도움이 되는 관련 조항은 어디에 있는지 알려주세요. 3.\n",
      "예를 들어, 의회, 대법원, 연방수사국(FBI), 중앙정보국(CIA), 국가안보국(NSA) 등\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# 모델과 토크나이저 로드\n",
    "model_name = \"maywell/Llama-3-Ko-8B-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "# 질문 문장 (원본 질문)\n",
    "original_question = \"대통령을 포함한 미국의 행정부 견제권을 갖는 국가 기관은?\"\n",
    "\n",
    "# 프롬프트 설정 (질문을 다른 표현으로 바꾸도록 유도)\n",
    "prompt = f\"질문: {original_question}\\n이 질문을 다른 표현으로 바꿔 주세요:\\n새로운 질문:\"\n",
    "\n",
    "# 입력을 토크나이징\n",
    "input_ids = tokenizer.encode(prompt, return_tensors='pt')\n",
    "\n",
    "# 모델로부터 새로운 질문 생성\n",
    "output = model.generate(input_ids, max_length=128, num_beams=5, no_repeat_ngram_size=2, early_stopping=True)\n",
    "\n",
    "# 생성된 문장을 디코딩\n",
    "paraphrased_question = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "print(f\"Original Question: {original_question}\")\n",
    "print(f\"Paraphrased Question: {paraphrased_question}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/ephemeral/home/miniconda3/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:35<00:00,  8.80s/it]\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Question: 대통령을 포함한 미국의 행정부 견제권을 갖는 국가 기관은?\n",
      "Paraphrased Question: 질문: 대통령을 포함한 미국의 행정부 견제권을 갖는 국가 기관은?\n",
      "이 질문을 다른 표현으로 바꿔 주세요:\n",
      "새로운 질문: 미국 헌법에서 대통령의 권한을 제한하기 위해 설립된 주요 기구는 무엇인가요?\n",
      "답변:\n",
      "1. **대법원 (U.S. Supreme Court)**:\n",
      "   - **역할**: 법률 해석 및 집행의 최종 판결을 내리는 역할을 담당합니다. 대통령에 대한 탄핵 소송을 심판할 수 있습니다.\n",
      "   2.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# 모델과 토크나이저 로드\n",
    "model_name = \"allganize/Llama-3-Alpha-Ko-8B-Instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "# 질문 문장 (원본 질문)\n",
    "original_question = \"대통령을 포함한 미국의 행정부 견제권을 갖는 국가 기관은?\"\n",
    "\n",
    "# 프롬프트 설정 (질문을 다른 표현으로 바꾸도록 유도)\n",
    "prompt = f\"질문: {original_question}\\n이 질문을 다른 표현으로 바꿔 주세요:\\n새로운 질문:\"\n",
    "\n",
    "# 입력을 토크나이징\n",
    "input_ids = tokenizer.encode(prompt, return_tensors='pt')\n",
    "\n",
    "# 모델로부터 새로운 질문 생성\n",
    "output = model.generate(input_ids, max_length=128, num_beams=5, no_repeat_ngram_size=2, early_stopping=True)\n",
    "\n",
    "# 생성된 문장을 디코딩\n",
    "paraphrased_question = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "print(f\"Original Question: {original_question}\")\n",
    "print(f\"Paraphrased Question: {paraphrased_question}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Question: 현대적 인사조직관리의 시발점이 된 책은?\n",
      "Paraphrased Question: 질문: 현대적 인사조직관리의 시발점이 된 책은?\n",
      "이 질문을 다른 표현으로 바꿔 주세요:\n",
      "새로운 질문: 20세기와 21세기의 인적 자원 관리 이론과 실천의 주요 출판물은 무엇인가요?\n",
      "현대적인 HRM의 기초를 다룬 책을 찾고 있습니다. 예를 들어, \"인사 조직 관리\"라는 제목의 책이 있지만, 이 질문에 대한 답변은 더 구체적이고 역사적 배경을 제공하는 것이 좋습니다.\n"
     ]
    }
   ],
   "source": [
    "# 질문 문장 (원본 질문)\n",
    "original_question = \"현대적 인사조직관리의 시발점이 된 책은?\"\n",
    "\n",
    "# 프롬프트 설정 (질문을 다른 표현으로 바꾸도록 유도)\n",
    "prompt = f\"질문: {original_question}\\n이 질문을 다른 표현으로 바꿔 주세요:\\n새로운 질문:\"\n",
    "\n",
    "# 입력을 토크나이징\n",
    "input_ids = tokenizer.encode(prompt, return_tensors='pt')\n",
    "\n",
    "# 모델로부터 새로운 질문 생성\n",
    "output = model.generate(input_ids, max_length=128, num_beams=5, no_repeat_ngram_size=2, early_stopping=True)\n",
    "\n",
    "# 생성된 문장을 디코딩\n",
    "paraphrased_question = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "print(f\"Original Question: {original_question}\")\n",
    "print(f\"Paraphrased Question: {paraphrased_question}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paraphrased Question: 20세기와 21세기의 인적 자원 관리 이론과 실천의 주요 출판물은 무엇인가요?\n"
     ]
    }
   ],
   "source": [
    "question_part = paraphrased_question.split(\"새로운 질문:\")[1].split('\\n')[0].strip()\n",
    "\n",
    "print(f\"Paraphrased Question: {question_part}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 3952/3952 [00:00<00:00, 215531.61 examples/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_from_disk, Dataset, DatasetDict\n",
    "\n",
    "dataset = load_from_disk(\"/data/ephemeral/home/jeongeun/data/raw/train_dataset\")\n",
    "train_dataset = dataset[\"train\"]\n",
    "train_df=pd.DataFrame(train_dataset)\n",
    "\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "\n",
    "dataset_dict = DatasetDict({\n",
    "    'train': train_dataset\n",
    "})\n",
    "\n",
    "dataset_dict.save_to_disk('/data/ephemeral/home/jeongeun/data/preprocessed/train_dataset')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
