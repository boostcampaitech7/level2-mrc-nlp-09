{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing - Add Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting konlpy\n",
      "  Downloading konlpy-0.6.0-py2.py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting JPype1>=0.7.0 (from konlpy)\n",
      "  Downloading JPype1-1.5.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting lxml>=4.1.0 (from konlpy)\n",
      "  Downloading lxml-5.3.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: numpy>=1.6 in /data/ephemeral/home/miniconda3/lib/python3.12/site-packages (from konlpy) (2.1.2)\n",
      "Requirement already satisfied: packaging in /data/ephemeral/home/miniconda3/lib/python3.12/site-packages (from JPype1>=0.7.0->konlpy) (24.1)\n",
      "Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.4/19.4 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading JPype1-1.5.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (488 kB)\n",
      "Downloading lxml-5.3.0-cp312-cp312-manylinux_2_28_x86_64.whl (4.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: lxml, JPype1, konlpy\n",
      "Successfully installed JPype1-1.5.0 konlpy-0.6.0 lxml-5.3.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable.It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install konlpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Kkma\n",
    "\n",
    "class QueryPreprocessor:\n",
    "    \"\"\"\n",
    "    Query 전처리 모듈화 클래스\n",
    "    전처리 방법을 모듈화하고, 전처리를 사용할지 여부를 제어할 수 있습니다.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.kkma = Kkma()\n",
    "\n",
    "    def preprocess(self, query: str) -> str:\n",
    "        \"\"\"\n",
    "        Query에 대한 전처리 작업을 수행하는 함수.\n",
    "        형태소 분석을 통해 의미 있는 태그(명사, 동사, 형용사 등)를 추출하고, \n",
    "        원래 query 앞에 공백으로 구분하여 추가합니다.\n",
    "        \"\"\"\n",
    "        # 의미 있는 품사 태그 목록\n",
    "        meaningful_pos_tags = ['NNG', 'NNP', 'VV', 'VA']\n",
    "        \n",
    "        # 형태소 분석 수행\n",
    "        tagged_tokens = self.kkma.pos(query)\n",
    "        \n",
    "        # 의미 있는 토큰 필터링\n",
    "        meaningful_tokens = [token for token, pos in tagged_tokens if pos in meaningful_pos_tags]\n",
    "        \n",
    "        # 의미 있는 토큰을 공백으로 구분하여 하나의 문자열로 연결\n",
    "        filtered_text = ' '.join(meaningful_tokens)\n",
    "        \n",
    "        # 기존 query에 필터링된 결과를 앞에 추가\n",
    "        processed_query = f\"{filtered_text} {query}\"\n",
    "        \n",
    "        return processed_query\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 29985/29985 [09:16<00:00, 53.83 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 29985/29985 [00:00<00:00, 274029.70 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_from_disk, DatasetDict\n",
    "\n",
    "\n",
    "dataset_path = \"/data/ephemeral/home/jeongeun/data/preprocessed/data1/train\"  # 저장된 데이터셋 경로를 지정하세요.\n",
    "dataset_dict = load_from_disk(dataset_path)\n",
    "\n",
    "# QueryPreprocessor 인스턴스 생성\n",
    "preprocessor = QueryPreprocessor()\n",
    "\n",
    "# 전처리 함수 적용\n",
    "def apply_preprocessing(example):\n",
    "    \"\"\"\n",
    "    각 데이터셋의 example에 대해 전처리 적용\n",
    "    \"\"\"\n",
    "    example[\"question\"] = preprocessor.preprocess(example[\"question\"])\n",
    "    return example\n",
    "\n",
    "# 데이터셋의 'train' split에 전처리 적용\n",
    "dataset_dict = dataset_dict.map(apply_preprocessing, batched=False)\n",
    "\n",
    "# 전처리된 데이터셋 저장\n",
    "processed_dataset_path = \"/data/ephemeral/home/jeongeun/data/preprocessed/data2/train\"  # 전처리된 데이터셋을 저장할 경로\n",
    "dataset_dict.save_to_disk(processed_dataset_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
